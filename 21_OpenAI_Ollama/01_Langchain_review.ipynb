{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Langchain and Open AI\n",
    "\n",
    "* In this quickstart is a how to:\n",
    "    1. Get setup with Langchain, langSmith and LangServe\n",
    "\n",
    "    2. Using basic and common components of LangChain: prompt templates, models, and outpu parsers\n",
    "    3. Build a simple application with LangChain\n",
    "    4. Trace your application with LangSmith\n",
    "    5. Serve your application with LangServe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Setting up OpenAI keys\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] =os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LangSmith Tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] =os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] =os.getenv(\"LANGCHAIN_PROJECT\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x11d4dd210> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11d351710> root_client=<openai.OpenAI object at 0x11d372390> root_async_client=<openai.AsyncOpenAI object at 0x11d4dd510> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# calling the model\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Graph Neural Networks (GNNs) for streaming graphs refer to the adaptation of GNN models to deal with dynamic or evolving graph data that arrives in a streaming fashion. Streaming graphs are characterized by their continuous and potentially unbounded nature, where nodes, edges, or features may be added, removed, or altered over time. Traditional GNNs, which are typically designed for static graphs, must be extended or modified to manage the temporal dynamics and scalability issues posed by streaming data. Here are some key considerations and methods used in GNNs for streaming graphs:\\n\\n1. **Dynamic Representation Learning**: The goal is to update node and edge embeddings efficiently as the graph changes. Techniques like temporal graph embeddings and incrementally updated GNNs are employed to reflect the most current graph structure and attributes.\\n\\n2. **Continuous Training**: To handle evolving data, models need mechanisms to retrain or fine-tune weights without starting from scratch. This could involve online learning approaches or incremental training strategies that keep the model up-to-date with minimal processing overhead.\\n\\n3. **Memory Efficiency**: Streaming graphs can grow large, so it's crucial to manage memory effectively. This can involve using data structures optimized for dynamic updates and pruning techniques to limit the memory footprint by focusing on the most relevant parts of the graph.\\n\\n4. **Scalability**: Handling large, dynamic graphs requires scalable GNN architectures. Distributed computing and parallel processing, along with efficient graph partitioning strategies, are often necessary to keep up with the data stream.\\n\\n5. **Temporal Dynamics**: Incorporating time-awareness in the model allows it to capture the temporal aspect of graphs. This can be done by adding temporal layers or using models specifically designed for spatio-temporal data, like recurrent neural networks (RNNs) combined with GNNs.\\n\\n6. **Event-based Processing**: Instead of processing the entire graph periodically, event-based processing allows the model to adjust only to the changes, significantly speeding up processing and reducing computational load.\\n\\nThere are various models specifically designed to handle these challenges, such as Temporal Graph Networks (TGNs) and Dynamic Graph Neural Networks (DGNNs). These models enable tasks like link prediction, node classification, and community detection to be performed efficiently and accurately on streaming graph data.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 456, 'prompt_tokens': 14, 'total_tokens': 470, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7e8d90e604', 'id': 'chatcmpl-BFBrH4BVFIFneK64jFjWSrKvokYrP', 'finish_reason': 'stop', 'logprobs': None} id='run-20b5040f-f24c-440a-a06c-2da28d3f6789-0' usage_metadata={'input_tokens': 14, 'output_tokens': 456, 'total_tokens': 470, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "result1 = llm.invoke('what is gnn for streaming graphs')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chapt-prompt Template\n",
    "\n",
    "* The ChatGPT Prompt Template is a structured format that helps guide the interaction with ChatGPT to generate specific and high-quality responses. It’s particularly useful when trying to achieve consistency, clarity, or focus in the generated content.\n",
    "\n",
    "### What is LLM prompt chains?\n",
    "* In the context of Large Language Models (LLMs), a `chain` refers to a **series of prompts or tasks that are connected together to accomplish a complex goal or generate multi-step outputs**. \n",
    "* It’s like a pipeline where the output of one step becomes the input for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions I have.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions I have.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Graph-based machine learning involves the use of graph structures to represent and analyze data, taking advantage of the relationships and connections between entities. Graphs are composed of nodes (or vertices) and edges, where nodes represent entities and edges represent the relationships between them. This approach is particularly useful for data that is inherently relational, such as social networks, molecular structures, transportation networks, and recommendation systems.\\n\\nHere's an overview of key concepts and techniques in graph-based machine learning:\\n\\n1. **Graph Representation:**\\n   - A graph \\\\( G = (V, E) \\\\) consists of a set of nodes \\\\( V \\\\) and a set of edges \\\\( E \\\\).\\n   - Graphs can be directed or undirected, weighted or unweighted, and may include additional attributes on nodes and edges.\\n\\n2. **Node Embeddings:**\\n   - These are vector representations of nodes, capturing the graph's structure and the nodes' properties.\\n   - Techniques include DeepWalk, node2vec, and Graph2Vec, which use random walks and embedding methods like Word2Vec.\\n\\n3. **Graph Neural Networks (GNNs):**\\n   - GNNs are designed to learn representations of graphs and their components.\\n   - Variants include Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), and GraphSAGE.\\n   - GNNs apply neural network architectures directly to graph-structured data, learning embeddings that capture the local graph structure.\\n\\n4. **Graph Convolutional Networks (GCN):**\\n   - GCNs extend the idea of convolutions from images to graphs.\\n   - They propagate and aggregate information from a node's neighborhood to compute its representation.\\n\\n5. **Graph Attention Networks (GAT):**\\n   - GATs use attention mechanisms to weigh the importance of different neighboring nodes during aggregation.\\n\\n6. **Applications:**\\n   - **Social Networks:** Analyzing influence, community detection, and friend recommendations.\\n   - **Biological Networks:** Modeling protein and gene interactions, drug discovery.\\n   - **Recommendation Systems:** Using user-item interaction graphs to provide personalized recommendations.\\n   - **Fraud Detection:** Detecting fraudulent activities by analyzing transaction networks.\\n\\n7. **Challenges and Considerations:**\\n   - **Scalability:** Graphs can be large and dense, leading to computational challenges.\\n   - **Dynamic Graphs:** Handling evolving graphs over time, which require methods for updating representations efficiently.\\n   - **Heterogeneous Graphs:** Dealing with graphs that include multiple types of nodes and edges.\\n\\nGraph-based machine learning provides a powerful framework for capturing complex relational data and has become increasingly significant in fields that require analyzing interconnected systems. The ongoing research in this area focuses on improving scalability, efficiency, and applicability to a wider range of problems.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 563, 'prompt_tokens': 36, 'total_tokens': 599, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7e8d90e604', 'id': 'chatcmpl-BFBrOL5819KlYAzxT3Qq1Qy0HfgKJ', 'finish_reason': 'stop', 'logprobs': None} id='run-aead1bd8-30a8-4cb7-9d76-3b7cfb0da8d9-0' usage_metadata={'input_tokens': 36, 'output_tokens': 563, 'total_tokens': 599, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#combining my prompt and llm model\n",
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Graph-based ml\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output Parsers\n",
    "* Output parsers in Large Language Models (LLMs) are tools or techniques used to structure, validate, and extract specific information from the raw text generated by an LLM. \n",
    "\n",
    "* They are essential for making sure the model's output is usable, accurate, and well-formatted for a particular application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! In the context of data representation, \"Graph ML\" and \"KG\" (Knowledge Graphs) refer to different but sometimes overlapping concepts:\n",
      "\n",
      "### 1. Graph ML:\n",
      "Graph Machine Learning (Graph ML) involves applying machine learning techniques specifically to graph-structured data. Various types of Graph ML methods can be used depending on the task at hand. Here are some key types:\n",
      "\n",
      "- **Graph Convolutional Networks (GCNs):** Inspired by convolutional networks in image processing, GCNs generalize convolutions to graph data, enabling the learning of node embeddings based on local neighborhood information.\n",
      "\n",
      "- **Graph Attention Networks (GATs):** An extension of GCNs that incorporates attention mechanisms, allowing the model to weigh the importance of neighboring nodes differently.\n",
      "\n",
      "- **Graph Recurrent Networks:** These networks handle dynamic graphs where the graph structure itself can change over time.\n",
      "\n",
      "- **Graph Autoencoders:** Used for unsupervised learning tasks like dimensionality reduction, these models learn to compress graph information and reconstruct the original graph.\n",
      "\n",
      "- **Graph Generative Models:** These models learn to generate new graphs from a learned representation, useful in applications like molecule generation in chemistry.\n",
      "\n",
      "- **Node, Edge, and Graph Classification:** Tasks that predict labels for nodes, edges, or entire graphs respectively, commonly using the aforementioned techniques.\n",
      "\n",
      "### 2. Knowledge Graphs (KG):\n",
      "Knowledge Graphs are structured representations of knowledge, typically in the form of entities (nodes) and the relationships (edges) between them. They can encompass a wide range of data, often designed to integrate information from multiple domains. Key types and components are:\n",
      "\n",
      "- **Taxonomies:** Simple hierarchies that classify entities into parent-child relationships, useful for representing structured data like categories or types.\n",
      "\n",
      "- **Ontologies:** Advanced structures that define entities, their attributes, and relationships, often augmented with rule-based reasoning capabilities.\n",
      "\n",
      "- **Semantic Networks:** Graphs where edges have explicit meanings, providing rich semantic relationships between nodes.\n",
      "\n",
      "- **Triple Stores/RDF Graphs:** Based on the Resource Description Framework (RDF), these consist of triples (subject, predicate, object) to capture relationships in a machine-readable format.\n",
      "\n",
      "- **Applications in Natural Language Processing (NLP):** KGs can help disambiguate entity references, enhance information retrieval, and support question-answering systems.\n",
      "\n",
      "- **Industry Applications:** Used extensively in fields such as healthcare, finance, and e-commerce for integration, knowledge discovery, and building AI systems with contextual awareness.\n",
      "\n",
      "Graph ML techniques can be combined with KGs to perform tasks like link prediction, entity classification, and more, enhancing the use and analysis of knowledge graphs through learning methodologies.\n"
     ]
    }
   ],
   "source": [
    "# str output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about types of Graph ml and kg\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
